# object/satellite.py
# ============================================================
# LEO ìœ„ì„± ë¹„ë™ê¸° ì—°í•©í•™ìŠµ ë¹„êµ ì‹¤í—˜
# 570km Walker-Delta: 17 planes Ã— 14 sats = 238 satellites
#
# 4ê°œ ì „ëµ ë¹„êµ (config.py AGGREGATION_STRATEGYë¡œ ì „í™˜):
#   1. FedAsync  - 1:1 ì¦‰ì‹œ ë¹„ë™ê¸° (Xie et al., 2019)
#   2. FedBuff   - K-ë²„í¼ pseudo-gradient averaging (Nguyen et al., 2022)
#   3. FedSpace  - ê¶¤ë„ ì¸ì‹ ë™ì  ìŠ¤ì¼€ì¤„ë§ (So et al., 2022)
#   4. FedOrbit  - Plane í´ëŸ¬ìŠ¤í„° + ë§ˆìŠ¤í„° ìœ„ì„± (Jabbarpour et al., 2024)
#
# ê³µí†µ ê°œì„ ì‚¬í•­:
#   - ë¯¸í•™ìŠµ ìœ„ì„± í•„í„°ë§
#   - Cosine Annealing LR
#   - LOCAL_TRAIN í›„ í‰ê°€ ì œê±°
#   - GLOBAL_TEST í‰ê°€ ì£¼ê¸° ì¡°ì ˆ
# ============================================================

import asyncio
import torch
import numpy as np
import math
from datetime import datetime, timedelta, timezone
from utils.skyfield_utils import EarthSatellite
from utils.logging_setup import setup_loggers, KST
from typing import Dict, List, Optional, Tuple
from pathlib import Path
from torch.utils.data import DataLoader
from collections import defaultdict, OrderedDict
from skyfield.api import load, wgs84

from config import (
    IOT_FLYOVER_THRESHOLD_DEG, GS_FLYOVER_THRESHOLD_DEG, LOCAL_EPOCHS,
    AGGREGATION_STRATEGY, NUM_PLANES, SATS_PER_PLANE, ORBIT_PERIOD_SEC,
    # FedAsync
    FEDASYNC_STALENESS_FUNC, FEDASYNC_ALPHA_MAX,
    # FedBuff
    FEDBUFF_K, FEDBUFF_SERVER_LR, FEDBUFF_SERVER_MOMENTUM,
    # FedSpace
    FEDSPACE_PREDICT_WINDOW_SEC, FEDSPACE_MIN_BUFFER, FEDSPACE_STALENESS_WEIGHT,
    # FedOrbit
    FEDORBIT_INTRA_AGG_INTERVAL_SEC, FEDORBIT_SERVER_LR,
    # Common
    BASE_LR, MIN_LR, EVAL_EVERY_N_ROUNDS, STALENESS_THRESHOLD,
    NUM_CLIENTS, DIRICHLET_ALPHA, BATCH_SIZE, SAMPLES_PER_CLIENT
)

from ml.data import get_cifar10_loaders
from ml.model import create_resnet9, PyTorchModel
from ml.training import train_model
from ml.aggregation import calculate_mixing_weight, weighted_update


class Satellite_Manager:
    """
    ìœ„ì„± ì—°í•©í•™ìŠµ ì‹œë®¬ë ˆì´ì…˜ ë§¤ë‹ˆì €.
    570km Walker-Delta (17Ã—14) constellationì—ì„œ
    FedAsync / FedBuff / FedSpace / FedOrbit 4ê°€ì§€ ì „ëµì„ ë¹„êµ ì‹¤í—˜í•©ë‹ˆë‹¤.
    """

    def __init__(self, start_time: datetime, end_time: datetime, sim_logger, perf_logger):
        self.start_time = start_time
        self.end_time = end_time
        self.sim_logger = sim_logger
        self.perf_logger = perf_logger

        self.satellites: Dict[int, EarthSatellite] = {}
        self.satellite_models: Dict[int, PyTorchModel] = {}
        self.satellite_performances: Dict[int, float] = {}
        self.satellite_last_trained_version: Dict[int, float] = {}

        # ìœ„ì„±ë³„ ê¸€ë¡œë²Œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹œì  ê¸°ë¡ (ì‹œê°„ ê¸°ë°˜ stalenessìš©)
        self.satellite_download_time: Dict[int, datetime] = {}

        self.check_arr = defaultdict(list)

        # --- FL ì„¤ì • ---
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        self.num_satellites = NUM_CLIENTS
        self.NUM_CLASSES = 10
        self.strategy = AGGREGATION_STRATEGY

        # --- Aggregation ìƒíƒœ ---
        self.aggregation_round = 0
        self.total_rounds = 0

        # FedBuff: pseudo-gradient ë²„í¼ + ì„œë²„ ëª¨ë©˜í…€
        self.gs_buffer: List[dict] = []
        self.server_momentum_state: Optional[OrderedDict] = None

        # FedSpace: ì ‘ì´‰ ì˜ˆì¸¡ ìºì‹œ
        self.gs_contact_schedule: List[dict] = []  # ì „ì²´ GS ì´ë²¤íŠ¸ (ì‹œê°„ìˆœ)

        # FedOrbit: plane í´ëŸ¬ìŠ¤í„° ìƒíƒœ
        self.plane_buffers: Dict[int, List[dict]] = defaultdict(list)  # planeë³„ ISL ë²„í¼
        self.plane_masters: Dict[int, int] = {}  # plane_id â†’ master_sat_id
        self.last_intra_agg_time: Dict[int, datetime] = {}  # planeë³„ ë§ˆì§€ë§‰ ISL ì§‘ê³„ ì‹œì 

        self.sim_logger.info(f"Strategy: {self.strategy.upper()}")
        self.sim_logger.info("CIFAR-10 ë°ì´í„°ì…‹ ë¡œë“œ ë° ìƒ˜í”Œë§ ì¤‘...")

        self.avg_data_count, self.client_subsets, self.val_loader, _ = get_cifar10_loaders(
            num_clients=self.num_satellites,
            dirichlet_alpha=DIRICHLET_ALPHA,
            data_root='./data',
            samples_per_client=SAMPLES_PER_CLIENT
        )
        self.sim_logger.info(f"ë°ì´í„°ì…‹ ë¡œë“œ ì™„ë£Œ. ìœ„ì„±ë‹¹ ë°ì´í„°: {self.avg_data_count:.0f}ì¥")

        self.global_model_net = create_resnet9(num_classes=self.NUM_CLASSES)
        self.global_model_net.to('cpu')
        self.global_model_wrapper = PyTorchModel.from_model(self.global_model_net, version=0.0)
        self.best_acc = 0.0

        self.sim_logger.info("ìœ„ì„± ê´€ë¦¬ì ìƒì„± ì™„ë£Œ.")

    # ================================================================
    # Walker-Delta Constellation ìœ í‹¸ë¦¬í‹°
    # ================================================================

    @staticmethod
    def get_plane_id(sat_id: int) -> int:
        """SAT01_01 â†’ sat_id=101 â†’ plane=1, SAT17_14 â†’ sat_id=1714 â†’ plane=17"""
        return sat_id // 100

    @staticmethod
    def get_position_in_plane(sat_id: int) -> int:
        """SAT01_01 â†’ position=1, SAT01_14 â†’ position=14"""
        return sat_id % 100

    def get_plane_satellites(self, plane_id: int) -> List[int]:
        """íŠ¹ì • planeì— ì†í•˜ëŠ” ëª¨ë“  ìœ„ì„± ID ë°˜í™˜"""
        return [sid for sid in self.satellites.keys() if self.get_plane_id(sid) == plane_id]

    # ================================================================
    # ê¶¤ë„/í†µì‹  ìŠ¤ì¼€ì¤„ (ëª¨ë“  ì „ëµ ê³µí†µ)
    # ================================================================

    def load_constellation(self):
        tle_path = "constellation.tle"
        satellites = {}
        try:
            with open(tle_path, "r") as f:
                lines = [line.strip() for line in f.readlines()]
                i = 0
                while i < len(lines):
                    if not lines[i]:
                        i += 1
                        continue
                    name, line1, line2 = lines[i:i + 3]
                    sat_id = int(name.replace("SAT", "").replace("_", ""))
                    satellites[sat_id] = EarthSatellite(line1, line2, name)
                    i += 3
            self.satellites = satellites
            self.sim_logger.info(
                f"Constellation ë¡œë“œ: {len(satellites)}ê°œ ìœ„ì„±, "
                f"{NUM_PLANES} planes Ã— {SATS_PER_PLANE} sats"
            )
        except Exception as e:
            self.sim_logger.error(f"TLE íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise e

    async def run(self):
        self.sim_logger.info("ìœ„ì„± ê´€ë¦¬ì ìš´ì˜ ì‹œì‘.")
        self.load_constellation()

        for sat_id in self.satellites.keys():
            self.satellite_models[sat_id] = PyTorchModel.from_model(self.global_model_net, version=0.0)
            self.satellite_performances[sat_id] = 0.0
            self.satellite_last_trained_version[sat_id] = -1.0
            self.satellite_download_time[sat_id] = self.start_time

        await self.propagate_orbit(self.start_time, self.end_time)
        self.sim_logger.info(f"ê¶¤ë„ ì „íŒŒ ì™„ë£Œ ({len(self.times)} steps).")

        await self.check_iot_comm()
        await self.check_gs_comm()
        self.sim_logger.info("ëª¨ë“  í†µì‹  ìŠ¤ì¼€ì¤„ ê³„ì‚° ì™„ë£Œ.")

        # FedOrbit: ë§ˆìŠ¤í„° ìœ„ì„± ì„ ì •
        if self.strategy == "fedorbit":
            self._fedorbit_init_masters()

        await self.manage_fl_process()
        self.sim_logger.info("ëª¨ë“  ì‹œë®¬ë ˆì´ì…˜ ì¢…ë£Œ.")

    async def propagate_orbit(self, start_time, end_time):
        step = timedelta(seconds=10)
        self.times = []
        curr = start_time
        while curr < end_time:
            self.times.append(curr)
            curr += step
        ts = load.timescale()
        self.t_vector = ts.from_datetimes(self.times)

    async def check_iot_comm(self):
        self.sim_logger.info("IoT í†µì‹  ê°€ëŠ¥ ì‹œê°„ ë¶„ì„ ì‹œì‘...")
        iot_devices = [
            {"name": "Amazon_Forest", "loc": wgs84.latlon(-3.47, -62.37, elevation_m=100)},
            {"name": "Great_Barrier_Reef", "loc": wgs84.latlon(-18.29, 147.77, elevation_m=0)},
            {"name": "Abisko Tundra", "loc": wgs84.latlon(68.35, 18.79, elevation_m=420)},
        ]
        for iot in iot_devices:
            for sat_id, satellite in self.satellites.items():
                difference = satellite - iot['loc']
                topocentric = difference.at(self.t_vector)
                alt, _, _ = topocentric.altaz()
                visible_indices = np.where(alt.degrees > IOT_FLYOVER_THRESHOLD_DEG)[0]
                if len(visible_indices) == 0:
                    continue
                breaks = np.where(np.diff(visible_indices) > 1)[0] + 1
                windows = np.split(visible_indices, breaks)
                for window in windows:
                    st = self.times[window[0]]
                    et = self.times[window[-1]]
                    dur = (et - st).total_seconds()
                    if dur == 0:
                        dur = 10
                    self.check_arr[sat_id].append({
                        "type": "IOT_TRAIN", "start_time": st, "end_time": et,
                        "duration": dur, "target": iot['name']
                    })

    async def check_gs_comm(self):
        self.sim_logger.info("ì§€ìƒêµ­ í†µì‹  ê°€ëŠ¥ ì‹œê°„ ë¶„ì„ ì‹œì‘...")
        gs = {"name": "Ground Station", "loc": wgs84.latlon(37.5665, 126.9780, elevation_m=34)}
        for sat_id, satellite in self.satellites.items():
            difference = satellite - gs['loc']
            topocentric = difference.at(self.t_vector)
            alt, _, _ = topocentric.altaz()
            visible_indices = np.where(alt.degrees > GS_FLYOVER_THRESHOLD_DEG)[0]
            if len(visible_indices) == 0:
                continue
            breaks = np.where(np.diff(visible_indices) > 1)[0] + 1
            windows = np.split(visible_indices, breaks)
            for window in windows:
                st = self.times[window[0]]
                et = self.times[window[-1]]
                dur = (et - st).total_seconds()
                if dur == 0:
                    dur = 10
                self.check_arr[sat_id].append({
                    "type": "GS_AGGREGATE", "start_time": st, "end_time": et,
                    "duration": dur, "target": gs['name']
                })

    # ================================================================
    # ê³µí†µ ìœ í‹¸ë¦¬í‹°
    # ================================================================

    def _get_cosine_lr(self) -> float:
        progress = min(self.aggregation_round / max(self.total_rounds, 1), 1.0)
        return MIN_LR + 0.5 * (BASE_LR - MIN_LR) * (1 + math.cos(math.pi * progress))

    def _evaluate_direct(self, model, data_loader, sat_id, version, stage):
        model.to(self.device)
        model.eval()
        criterion = torch.nn.CrossEntropyLoss()
        correct, total, total_loss = 0, 0, 0.0
        with torch.no_grad():
            for images, labels in data_loader:
                images, labels = images.to(self.device), labels.to(self.device)
                outputs = model(images)
                loss = criterion(outputs, labels)
                total_loss += loss.item()
                _, predicted = torch.max(outputs.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()
        acc = 100 * correct / total
        avg_loss = total_loss / len(data_loader) if len(data_loader) > 0 else 0
        self.perf_logger.info(
            f"{datetime.now(KST).isoformat()},{stage},{sat_id},{version:.2f},"
            f"{self.strategy},{acc:.4f},{avg_loss:.6f},0.0000"
        )
        model.to('cpu')
        return acc, avg_loss

    def _is_trained_since_global(self, sat_id) -> bool:
        return self.satellite_last_trained_version[sat_id] > self.global_model_wrapper.version

    @staticmethod
    def _is_gradient_param(key: str, tensor: torch.Tensor) -> bool:
        """pseudo-gradient ì—°ì‚° ëŒ€ìƒì¸ì§€ íŒë³„.
        BatchNormì˜ num_batches_tracked(int64) ë“± non-float í…ì„œëŠ” ì œì™¸."""
        return tensor.is_floating_point()

    def _staleness_function(self, staleness: float) -> float:
        """s(Ï„) = 1/(1+Ï„)^0.5 â€” FedAsync/FedBuff ê³µí†µ"""
        if FEDASYNC_STALENESS_FUNC == "poly":
            return (1.0 + staleness) ** (-0.5)
        elif FEDASYNC_STALENESS_FUNC == "hinge":
            return 1.0 if staleness <= STALENESS_THRESHOLD else 0.0
        else:
            return 1.0

    def _compute_staleness(self, local_wrapper, event_time: datetime) -> Tuple[float, float]:
        """
        ìœ„ì„± íŠ¹í™” staleness: ë²„ì „ ê¸°ë°˜ + ì‹œê°„ ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ
        Returns: (Ï„_version, Ï„_time_normalized)
        """
        Ï„_ver = max(0, self.global_model_wrapper.version - int(local_wrapper.version))
        # ì‹œê°„ ê¸°ë°˜: ë‹¤ìš´ë¡œë“œ ì‹œì ìœ¼ë¡œë¶€í„° ê²½ê³¼ ì‹œê°„ / ê¶¤ë„ ì£¼ê¸°
        # (í˜„ì¬ëŠ” Ï„_verë§Œ staleness functionì— ì‚¬ìš©, Ï„_timeì€ ë¡œê¹…ìš©)
        return Ï„_ver, 0.0

    def _update_global_and_evaluate(self, new_state_dict, new_version,
                                     participating_ids, temp_model, force_eval=False):
        """ê¸€ë¡œë²Œ ëª¨ë¸ ì—…ë°ì´íŠ¸ + í‰ê°€ + ì²´í¬í¬ì¸íŠ¸ (ê³µí†µ)"""
        self.global_model_net.load_state_dict(new_state_dict)

        if force_eval or (self.aggregation_round % EVAL_EVERY_N_ROUNDS == 0):
            temp_model.load_state_dict(new_state_dict)
            g_acc, g_loss = self._evaluate_direct(
                temp_model, self.val_loader, sat_id="GS",
                version=new_version, stage="GLOBAL_TEST"
            )
            if g_acc > self.best_acc:
                prev = self.best_acc
                self.best_acc = g_acc
                save_dir = Path("./checkpoints")
                save_dir.mkdir(parents=True, exist_ok=True)
                torch.save({
                    'model_state_dict': new_state_dict,
                    'version': new_version,
                    'accuracy': g_acc, 'loss': g_loss,
                    'round': self.aggregation_round,
                    'strategy': self.strategy,
                    'participants': participating_ids,
                }, save_dir / f"{self.strategy}_v{int(new_version)}_acc{g_acc:.2f}.pth")
                self.sim_logger.info(f"   ğŸ’¾ New Best! ({prev:.2f}% â†’ {g_acc:.2f}%)")
            self.sim_logger.info(
                f"   ğŸ“Š Round #{self.aggregation_round}: v{new_version:.0f} Acc: {g_acc:.2f}%"
            )
        else:
            self.sim_logger.info(
                f"   ğŸ“Š Round #{self.aggregation_round}: v{new_version:.0f} (í‰ê°€ ìŠ¤í‚µ)"
            )

        self.global_model_wrapper = PyTorchModel(
            version=new_version,
            model_state_dict=new_state_dict,
            trained_by=self.global_model_wrapper.trained_by + participating_ids
        )

    # ================================================================
    # Strategy 1: FedAsync (Xie et al., 2019)
    #
    # GS ì ‘ì´‰ ì¦‰ì‹œ 1:1 ê°€ì¤‘ í‰ê· .
    # x_t = (1 - Î±_eff) * x_global + Î±_eff * x_local
    # Î±_eff = Î±_dynamic Ã— s(Ï„), s(Ï„) = (1+Ï„)^(-0.5)
    # ================================================================

    def _fedasync_aggregate(self, sat_id, local_wrapper, temp_model, event_time):
        self.aggregation_round += 1
        new_version = round(self.global_model_wrapper.version + 1.0, 1)

        Ï„_ver, Ï„_time = self._compute_staleness(local_wrapper, event_time)
        s_tau = self._staleness_function(Ï„_ver)

        loader_idx = sat_id % len(self.client_subsets)
        local_data_count = len(self.client_subsets[loader_idx])
        local_acc = self.satellite_performances.get(sat_id, 0.0)

        alpha_dyn, _, _, _ = calculate_mixing_weight(
            local_ver=local_wrapper.version,
            global_ver=self.global_model_wrapper.version,
            local_acc=local_acc, global_acc=self.best_acc,
            local_data_count=local_data_count,
            avg_data_count=self.avg_data_count
        )
        alpha_eff = min(alpha_dyn * s_tau, FEDASYNC_ALPHA_MAX)

        self.sim_logger.info(
            f"   âš¡ [FedAsync] Î±={alpha_dyn:.4f}Ã—s(Ï„={Ï„_ver})={s_tau:.3f} â†’ Î±_eff={alpha_eff:.4f}"
        )

        new_sd = weighted_update(
            self.global_model_wrapper.model_state_dict,
            local_wrapper.model_state_dict, alpha_eff
        )
        self._update_global_and_evaluate(new_sd, new_version, [sat_id], temp_model)

        self.satellite_models[sat_id] = PyTorchModel.from_model(
            self.global_model_net, version=new_version
        )
        self.satellite_last_trained_version[sat_id] = -1.0
        self.satellite_download_time[sat_id] = event_time

    # ================================================================
    # Strategy 2: FedBuff (Nguyen et al., 2022)
    #
    # ë…¼ë¬¸ ì›ë³¸ pseudo-gradient averaging:
    #   Client: Î”_i = w_before - w_after (pseudo-gradient)
    #   Server: Kê°œ ëª¨ì´ë©´ Î”_avg = (1/K) Î£ s(Ï„_i)Â·Î”_i
    #           w_{t+1} = w_t - Î·_g Â· Î”_avg
    #   ì„œë²„ ëª¨ë©˜í…€: m_t = Î²Â·m_{t-1} + Î”_avg, w_{t+1} = w_t - Î·_gÂ·m_t
    # ================================================================

    def _fedbuff_collect(self, sat_id, local_wrapper, event_time):
        """ë²„í¼ì— pseudo-gradient ìˆ˜ì§‘"""
        Ï„_ver, _ = self._compute_staleness(local_wrapper, event_time)
        s_tau = self._staleness_function(Ï„_ver)

        # pseudo-gradient: Î” = w_download - w_trained
        # local_wrapperì˜ base version(ì •ìˆ˜ë¶€) ì‹œì ì˜ ê¸€ë¡œë²Œ ëª¨ë¸ì´ w_download
        # í˜„ì¬ëŠ” local_wrapper.model_state_dictê°€ w_trained
        # w_downloadëŠ” satelliteê°€ ë‹¤ìš´ë¡œë“œí•œ ê¸€ë¡œë²Œ ëª¨ë¸ â†’ ë²„ì „ ê¸°ë°˜ ì¶”ì 
        # ê°„ì†Œí™”: global modelì˜ í˜„ì¬ stateë¥¼ w_referenceë¡œ ì‚¬ìš©í•˜ì§€ ì•Šê³ ,
        # ìœ„ì„±ì´ í•™ìŠµ ì‹œì‘ ì‹œ ë‹¤ìš´ë¡œë“œí•œ ëª¨ë¸ ê¸°ì¤€ìœ¼ë¡œ Î”ë¥¼ ê³„ì‚°í•´ì•¼ í•¨.
        # ê·¸ëŸ¬ë‚˜ ê·¸ ì‹œì ì˜ ê¸€ë¡œë²Œ ëª¨ë¸ì„ ì €ì¥í•˜ê³  ìˆì§€ ì•Šìœ¼ë¯€ë¡œ,
        # pseudo-gradientë¥¼ ì§ì ‘ ì €ì¥í•˜ëŠ” ëŒ€ì‹  model state ìì²´ë¥¼ ì €ì¥í•˜ê³ 
        # flush ì‹œì ì— í˜„ì¬ ê¸€ë¡œë²Œê³¼ì˜ ì°¨ì´ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.

        loader_idx = sat_id % len(self.client_subsets)
        local_data_count = len(self.client_subsets[loader_idx])

        self.gs_buffer.append({
            "sat_id": sat_id,
            "state_dict": local_wrapper.model_state_dict,
            "base_version": int(local_wrapper.version),  # í•™ìŠµ ì‹œì‘ ì‹œ ê¸€ë¡œë²Œ ë²„ì „
            "staleness": Ï„_ver,
            "s_tau": s_tau,
            "data_count": local_data_count,
        })
        self.sim_logger.info(
            f"   ğŸ“¦ ë²„í¼ ì¶”ê°€ (v{local_wrapper.version:.1f}, "
            f"Ï„={Ï„_ver}, ë²„í¼: {len(self.gs_buffer)}/{FEDBUFF_K})"
        )

    def _fedbuff_flush(self, temp_model, force_eval=False):
        """Kê°œ ëª¨ì˜€ì„ ë•Œ pseudo-gradient averagingìœ¼ë¡œ ì§‘ê³„"""
        if len(self.gs_buffer) == 0:
            return

        self.aggregation_round += 1
        new_version = round(self.global_model_wrapper.version + 1.0, 1)
        K = len(self.gs_buffer)
        participating_ids = [m["sat_id"] for m in self.gs_buffer]

        self.sim_logger.info(
            f"\nâš¡ [FedBuff Round #{self.aggregation_round}] K={K}: {participating_ids}"
        )

        global_sd = self.global_model_wrapper.model_state_dict

        # pseudo-gradient ê³„ì‚° ë° staleness-weighted í‰ê· 
        # Î”_avg = (1/K) * Î£ s(Ï„_i) * Î”_i
        # Î”_i = global_at_base_version - local_trained â‰ˆ global_current - local_trained
        # (base versionì˜ ê¸€ë¡œë²Œ ëª¨ë¸ì´ ì—†ìœ¼ë¯€ë¡œ í˜„ì¬ ê¸€ë¡œë²Œ ê¸°ì¤€ ê·¼ì‚¬)
        delta_avg = OrderedDict()
        total_s = sum(m["s_tau"] for m in self.gs_buffer)
        if total_s == 0:
            total_s = float(K)

        for key in global_sd.keys():
            if not self._is_gradient_param(key, global_sd[key]):
                # num_batches_tracked ë“± non-float â†’ ê¸€ë¡œë²Œ ê°’ ê·¸ëŒ€ë¡œ ìœ ì§€
                delta_avg[key] = None
                continue
            delta = torch.zeros_like(global_sd[key], dtype=torch.float32)
            for m in self.gs_buffer:
                pseudo_grad = global_sd[key].float() - m["state_dict"][key].float()
                delta += (m["s_tau"] / total_s) * pseudo_grad

                self.sim_logger.debug(f"   SAT_{m['sat_id']}: s(Ï„={m['staleness']})={m['s_tau']:.3f}")
            delta_avg[key] = delta

        # ì„œë²„ ëª¨ë©˜í…€ ì ìš©: m_t = Î²Â·m_{t-1} + Î”_avg
        Î² = FEDBUFF_SERVER_MOMENTUM
        if self.server_momentum_state is None:
            self.server_momentum_state = OrderedDict()
            for key in delta_avg:
                if delta_avg[key] is not None:
                    self.server_momentum_state[key] = delta_avg[key].clone()
        else:
            for key in delta_avg:
                if delta_avg[key] is not None and key in self.server_momentum_state:
                    self.server_momentum_state[key] = (
                        Î² * self.server_momentum_state[key] + delta_avg[key]
                    )

        # w_{t+1} = w_t - Î·_g Â· m_t
        Î·_g = FEDBUFF_SERVER_LR
        new_sd = OrderedDict()
        for key in global_sd.keys():
            if not self._is_gradient_param(key, global_sd[key]):
                new_sd[key] = global_sd[key].clone()  # non-float: ì›ë³¸ dtype ìœ ì§€
            elif key in self.server_momentum_state:
                new_sd[key] = (
                    global_sd[key].float() - Î·_g * self.server_momentum_state[key]
                ).to(global_sd[key].dtype).cpu()
            else:
                new_sd[key] = global_sd[key].clone()

        self.sim_logger.info(f"   ğŸ“ Î·_g={Î·_g}, Î²={Î²}, K={K}")

        self._update_global_and_evaluate(new_sd, new_version, participating_ids, temp_model, force_eval)

        # ì°¸ì—¬ ìœ„ì„± ë™ê¸°í™”
        for m in self.gs_buffer:
            self.satellite_models[m["sat_id"]] = PyTorchModel.from_model(
                self.global_model_net, version=new_version
            )
            self.satellite_last_trained_version[m["sat_id"]] = -1.0

        self.gs_buffer = []

    # ================================================================
    # Strategy 3: FedSpace (So et al., 2022)
    #
    # í•µì‹¬: ê¶¤ë„ ì˜ˆì¸¡ìœ¼ë¡œ í–¥í›„ GS ì ‘ì´‰ ë°€ë„ë¥¼ íŒŒì•…í•˜ê³ ,
    # staleness-idleness trade-offë¥¼ ë™ì ìœ¼ë¡œ ìµœì í™”í•˜ì—¬ ì§‘ê³„ ì‹œì  ê²°ì •.
    #
    # - ì ‘ì´‰ ë°€ì§‘ êµ¬ê°„: ë” ëª¨ì•„ì„œ ì•ˆì •ì  ì§‘ê³„ (staleness ìµœì†Œí™”)
    # - ì ‘ì´‰ í¬ì†Œ êµ¬ê°„: ë¹¨ë¦¬ ì§‘ê³„ (idleness ìµœì†Œí™”)
    # ================================================================

    def _fedspace_predict_upcoming_contacts(self, current_time, window_sec=None) -> int:
        """í˜„ì¬ ì‹œì ì—ì„œ í–¥í›„ window_sec ë‚´ ì˜ˆìƒ GS ì ‘ì´‰ ìˆ˜"""
        if window_sec is None:
            window_sec = FEDSPACE_PREDICT_WINDOW_SEC
        deadline = current_time + timedelta(seconds=window_sec)
        count = 0
        for evt in self.gs_contact_schedule:
            if evt["start_time"] > deadline:
                break
            if evt["start_time"] > current_time:
                count += 1
        return count

    def _fedspace_should_flush(self, current_time, buffer_size, is_last=False) -> bool:
        """FedSpace ë™ì  flush íŒë‹¨"""
        if is_last or buffer_size <= 0:
            return is_last and buffer_size > 0

        # í–¥í›„ ì ‘ì´‰ ì˜ˆì¸¡
        upcoming = self._fedspace_predict_upcoming_contacts(current_time)

        # Staleness ìš°ì„ (ë§ì´ ëª¨ìœ¼ê¸°) vs Idleness ìš°ì„ (ë¹¨ë¦¬ ì§‘ê³„)
        w = FEDSPACE_STALENESS_WEIGHT  # 0~1, ë†’ì„ìˆ˜ë¡ staleness ìš°ì„ 

        # ì ‘ì´‰ì´ ë§ì´ ì˜ˆìƒë˜ë©´ â†’ ë” ëª¨ìŒ (threshold ë†’ì„)
        # ì ‘ì´‰ì´ ì ìœ¼ë©´ â†’ ë¹¨ë¦¬ ì§‘ê³„ (threshold ë‚®ì¶¤)
        dynamic_threshold = max(
            FEDSPACE_MIN_BUFFER,
            int(FEDSPACE_MIN_BUFFER + w * min(upcoming, 15))
        )

        should = buffer_size >= dynamic_threshold
        if should:
            self.sim_logger.info(
                f"   ğŸŒ [FedSpace] ì§‘ê³„ ê²°ì •: ë²„í¼={buffer_size} â‰¥ "
                f"threshold={dynamic_threshold} (í–¥í›„ ì ‘ì´‰ {upcoming}ê°œ)"
            )
        return should

    def _fedspace_aggregate(self, temp_model, force_eval=False):
        """FedSpace: FedBuffì™€ ë™ì¼í•œ pseudo-gradient ë°©ì‹, ì‹œì ë§Œ ë‹¤ë¦„"""
        self._fedbuff_flush(temp_model, force_eval)

    # ================================================================
    # Strategy 4: FedOrbit (Jabbarpour et al., 2024)
    #
    # í•µì‹¬ êµ¬ì„±:
    #   1. Plane-based Clustering: 17ê°œ orbital plane = 17ê°œ í´ëŸ¬ìŠ¤í„°
    #   2. Master Satellite: plane ë‚´ GS ì ‘ì´‰ ë¹ˆë„ ìµœë‹¤ ìœ„ì„±
    #   3. Intra-Plane ISL Aggregation: plane ë‚´ ìœ„ì„±ë“¤ì´ ISLë¡œ ëª¨ë¸ êµí™˜
    #   4. Master â†’ GS Upload: ë§ˆìŠ¤í„°ê°€ plane ëŒ€í‘œ ëª¨ë¸ì„ GSì— ì „ì†¡
    #
    # ì›ë…¼ë¬¸ì€ RLë¡œ í´ëŸ¬ìŠ¤í„°ë¥¼ í˜•ì„±í•˜ì§€ë§Œ, Walker-Deltaì—ì„œëŠ”
    # orbital planeì´ ìì—°ìŠ¤ëŸ¬ìš´ í´ëŸ¬ìŠ¤í„°ì´ë¯€ë¡œ ê²°ì •ë¡ ì ìœ¼ë¡œ êµ¬ì„±.
    # ================================================================

    def _fedorbit_init_masters(self):
        """ê° planeì—ì„œ GS ì ‘ì´‰ ë¹ˆë„ê°€ ê°€ì¥ ë†’ì€ ìœ„ì„±ì„ ë§ˆìŠ¤í„°ë¡œ ì„ ì •"""
        plane_gs_count = defaultdict(lambda: defaultdict(int))

        for sat_id, events in self.check_arr.items():
            plane = self.get_plane_id(sat_id)
            gs_contacts = sum(1 for e in events if e["type"] == "GS_AGGREGATE")
            plane_gs_count[plane][sat_id] = gs_contacts

        for plane_id in range(1, NUM_PLANES + 1):
            if plane_id in plane_gs_count and plane_gs_count[plane_id]:
                master = max(plane_gs_count[plane_id], key=plane_gs_count[plane_id].get)
                self.plane_masters[plane_id] = master
                self.last_intra_agg_time[plane_id] = self.start_time
                self.sim_logger.info(
                    f"   ğŸ›°ï¸ Plane {plane_id}: Master=SAT_{master} "
                    f"(GSì ‘ì´‰ {plane_gs_count[plane_id][master]}íšŒ)"
                )

    def _fedorbit_intra_plane_collect(self, sat_id, local_wrapper, event_time):
        """
        Intra-Plane ISL ë²„í¼ì— ìˆ˜ì§‘.
        ì‹¤ì œë¡œëŠ” ISLì„ í†µí•´ ê°™ì€ plane ë‚´ì—ì„œ êµí™˜í•˜ì§€ë§Œ,
        ì‹œë®¬ë ˆì´ì…˜ì—ì„œëŠ” plane ë²„í¼ì— ëª¨ë¸ì„ ì¶”ê°€í•˜ëŠ” ê²ƒìœ¼ë¡œ ëª¨ì‚¬.
        """
        plane_id = self.get_plane_id(sat_id)
        loader_idx = sat_id % len(self.client_subsets)

        self.plane_buffers[plane_id].append({
            "sat_id": sat_id,
            "state_dict": local_wrapper.model_state_dict,
            "version": local_wrapper.version,
            "data_count": len(self.client_subsets[loader_idx]),
        })

    def _fedorbit_try_intra_aggregate(self, plane_id, event_time, temp_model):
        """
        Plane ë‚´ ISL ì§‘ê³„: ì£¼ê¸°ì ìœ¼ë¡œ plane ë‚´ ëª¨ë¸ë“¤ì„ í•©ì¹¨.
        ë§ˆìŠ¤í„° ìœ„ì„±ì´ GSì— ì ‘ì´‰í•  ë•Œ ì´ ê²°ê³¼ë¥¼ ì—…ë¡œë“œ.
        """
        buf = self.plane_buffers[plane_id]
        if len(buf) == 0:
            return None

        # ë§ˆì§€ë§‰ ì§‘ê³„ ì´í›„ ì¶©ë¶„í•œ ì‹œê°„ì´ ì§€ë‚¬ëŠ”ì§€ í™•ì¸
        elapsed = (event_time - self.last_intra_agg_time.get(plane_id, self.start_time)).total_seconds()
        if elapsed < FEDORBIT_INTRA_AGG_INTERVAL_SEC and len(buf) < SATS_PER_PLANE:
            return None

        self.last_intra_agg_time[plane_id] = event_time

        # Intra-plane FedAvg (ê°™ì€ planeì´ë¯€ë¡œ staleness ì°¨ì´ ì ìŒ â†’ ë‹¨ìˆœ ê°€ì¤‘í‰ê· )
        total_data = sum(m["data_count"] for m in buf)
        if total_data == 0:
            total_data = len(buf)

        aggregated = OrderedDict()
        for key in buf[0]["state_dict"].keys():
            if not self._is_gradient_param(key, buf[0]["state_dict"][key]):
                # non-float (num_batches_tracked ë“±): ì²« ë²ˆì§¸ ìœ„ì„± ê°’ ì‚¬ìš©
                aggregated[key] = buf[0]["state_dict"][key].clone()
                continue
            param = torch.zeros_like(buf[0]["state_dict"][key], dtype=torch.float32)
            for m in buf:
                w = m["data_count"] / total_data
                param += w * m["state_dict"][key].float()
            aggregated[key] = param.to(buf[0]["state_dict"][key].dtype).cpu()

        self.sim_logger.info(
            f"   ğŸ”— [FedOrbit ISL] Plane {plane_id}: "
            f"{len(buf)}ê°œ ìœ„ì„± intra-plane ì§‘ê³„ ì™„ë£Œ"
        )

        # ë²„í¼ í´ë¦¬ì–´ ë° ì°¸ì—¬ ìœ„ì„± ë™ê¸°í™”
        participating = [m["sat_id"] for m in buf]
        self.plane_buffers[plane_id] = []

        return {"state_dict": aggregated, "participants": participating, "plane_id": plane_id}

    def _fedorbit_master_upload(self, sat_id, local_wrapper, event_time, temp_model):
        """
        ë§ˆìŠ¤í„° ìœ„ì„±ì´ GS ì ‘ì´‰ ì‹œ:
        1) plane ë‚´ ISL ì§‘ê³„ ì‹¤í–‰ (IOT_TRAINì—ì„œ ì´ë¯¸ ìˆ˜ì§‘ëœ ë²„í¼ ì‚¬ìš©)
        2) ì§‘ê³„ ê²°ê³¼ë¥¼ pseudo-gradientë¡œ ë³€í™˜í•˜ì—¬ ê¸€ë¡œë²Œ ì—…ë°ì´íŠ¸
        """
        plane_id = self.get_plane_id(sat_id)

        # Intra-plane ì§‘ê³„ ê°•ì œ ì‹¤í–‰
        self.last_intra_agg_time[plane_id] = self.start_time  # ê°•ì œ flush
        result = self._fedorbit_try_intra_aggregate(plane_id, event_time, temp_model)

        if result is None:
            return False

        # Plane ëŒ€í‘œ ëª¨ë¸ â†’ ê¸€ë¡œë²Œ ì—…ë°ì´íŠ¸ (pseudo-gradient ë°©ì‹)
        self.aggregation_round += 1
        new_version = round(self.global_model_wrapper.version + 1.0, 1)

        global_sd = self.global_model_wrapper.model_state_dict
        plane_sd = result["state_dict"]

        # pseudo-gradient: Î” = global - plane_aggregated
        Î·_g = FEDORBIT_SERVER_LR
        new_sd = OrderedDict()
        for key in global_sd.keys():
            if not self._is_gradient_param(key, global_sd[key]):
                new_sd[key] = global_sd[key].clone()
                continue
            delta = global_sd[key].float() - plane_sd[key].float()
            new_sd[key] = (global_sd[key].float() - Î·_g * delta).to(global_sd[key].dtype).cpu()

        self.sim_logger.info(
            f"   ğŸš€ [FedOrbit] Plane {plane_id} Master SAT_{sat_id} â†’ GS Upload "
            f"({len(result['participants'])}ê°œ ìœ„ì„±)"
        )

        self._update_global_and_evaluate(
            new_sd, new_version, result["participants"], temp_model
        )

        # Plane ë‚´ ëª¨ë“  ìœ„ì„± ë™ê¸°í™”
        for sid in self.get_plane_satellites(plane_id):
            self.satellite_models[sid] = PyTorchModel.from_model(
                self.global_model_net, version=new_version
            )
            self.satellite_last_trained_version[sid] = -1.0
            self.satellite_download_time[sid] = event_time

        return True

    # ================================================================
    # ë©”ì¸ FL í”„ë¡œì„¸ìŠ¤
    # ================================================================

    async def manage_fl_process(self):
        self.sim_logger.info(
            f"\n=== ì—°í•© í•™ìŠµ ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘ [{self.strategy.upper()}] ==="
        )

        # ì „ì²´ ì´ë²¤íŠ¸ ì‹œê°„ìˆœ ì •ë ¬
        all_events = []
        for sat_id, events in self.check_arr.items():
            for event in events:
                event['sat_id'] = sat_id
                all_events.append(event)
        all_events.sort(key=lambda x: x['start_time'])

        # FedSpace: GS ì ‘ì´‰ ìŠ¤ì¼€ì¤„ ìºì‹± (ì ‘ì´‰ ì˜ˆì¸¡ìš©)
        self.gs_contact_schedule = [e for e in all_events if e['type'] == 'GS_AGGREGATE']

        self.total_rounds = sum(1 for e in all_events if e['type'] == 'GS_AGGREGATE')
        self.sim_logger.info(
            f"ğŸ“… ì´ {len(all_events)}ê°œ ì´ë²¤íŠ¸ "
            f"(IOT: {len(all_events)-self.total_rounds}, GS: {self.total_rounds}) | "
            f"Strategy: {self.strategy}"
        )

        temp_model = create_resnet9(num_classes=self.NUM_CLASSES)

        for i, event in enumerate(all_events):
            sat_id = event['sat_id']
            current_local_wrapper = self.satellite_models[sat_id]
            event_time = event['start_time']

            # â”€â”€â”€ IOT_TRAIN (ê³µí†µ) â”€â”€â”€
            if event['type'] == 'IOT_TRAIN':
                self.sim_logger.info(
                    f"\nğŸ“¡ [{event_time.strftime('%m-%d %H:%M')}] "
                    f"SAT_{sat_id} : IoT í•™ìŠµ ({event['target']})"
                )

                loader_idx = sat_id % len(self.client_subsets)
                dataset = self.client_subsets[loader_idx]
                train_loader = DataLoader(
                    dataset, batch_size=BATCH_SIZE, shuffle=True,
                    num_workers=8, pin_memory=True, persistent_workers=False
                )
                current_local_wrapper.to_device(temp_model, device='cpu')
                current_lr = self._get_cosine_lr()

                train_model(
                    model=temp_model,
                    global_state_dict=self.global_model_wrapper.model_state_dict,
                    train_loader=train_loader,
                    epochs=LOCAL_EPOCHS, lr=current_lr,
                    device=self.device, sim_logger=self.sim_logger
                )

                next_version = round(current_local_wrapper.version + 0.1, 1)
                current_local_wrapper = PyTorchModel.from_model(temp_model, version=next_version)
                self.satellite_models[sat_id] = current_local_wrapper
                self.satellite_last_trained_version[sat_id] = next_version

                self.sim_logger.info(
                    f"   âœ… SAT_{sat_id} í•™ìŠµ ì™„ë£Œ (LR: {current_lr:.4f}, v{next_version:.1f})"
                )

                # FedOrbit: í•™ìŠµ ì™„ë£Œ ì‹œ plane ë²„í¼ì— ìë™ ìˆ˜ì§‘
                if self.strategy == "fedorbit":
                    self._fedorbit_intra_plane_collect(sat_id, current_local_wrapper, event_time)

            # â”€â”€â”€ GS_AGGREGATE (ì „ëµ ë¶„ê¸°) â”€â”€â”€
            elif event['type'] == 'GS_AGGREGATE':
                self.sim_logger.info(
                    f"\nğŸ“¡ [{event_time.strftime('%m-%d %H:%M')}] "
                    f"SAT_{sat_id} : ì§€ìƒêµ­ ì ‘ì†"
                )

                # [ê³µí†µ] ë¯¸í•™ìŠµ ìœ„ì„± í•„í„°ë§
                if not self._is_trained_since_global(sat_id):
                    if self.global_model_wrapper.version > current_local_wrapper.version:
                        self.satellite_models[sat_id] = PyTorchModel.from_model(
                            self.global_model_net, version=self.global_model_wrapper.version
                        )
                        self.satellite_download_time[sat_id] = event_time
                        self.sim_logger.info(
                            f"   ğŸ“¥ SAT_{sat_id}: ë¯¸í•™ìŠµ â†’ v{self.global_model_wrapper.version} ë‹¤ìš´ë¡œë“œ"
                        )
                    else:
                        self.sim_logger.info(f"   â­ï¸ SAT_{sat_id}: ë¯¸í•™ìŠµ & ìµœì‹  â†’ Skip")

                    # FedOrbit: ë§ˆìŠ¤í„°ì¸ ê²½ìš° plane ë²„í¼ê°€ ìˆìœ¼ë©´ ì—…ë¡œë“œ ì‹œë„
                    if self.strategy == "fedorbit":
                        plane = self.get_plane_id(sat_id)
                        if self.plane_masters.get(plane) == sat_id and len(self.plane_buffers[plane]) > 0:
                            self._fedorbit_master_upload(sat_id, current_local_wrapper, event_time, temp_model)
                    continue

                # [ê³µí†µ] Staleness ì´ˆê³¼ â†’ ë‹¤ìš´ë¡œë“œë§Œ
                if self.global_model_wrapper.version > current_local_wrapper.version + STALENESS_THRESHOLD:
                    self.satellite_models[sat_id] = PyTorchModel.from_model(
                        self.global_model_net, version=self.global_model_wrapper.version
                    )
                    self.satellite_last_trained_version[sat_id] = -1.0
                    self.satellite_download_time[sat_id] = event_time
                    self.sim_logger.info(
                        f"   ğŸ“¥ SAT_{sat_id}: Stale â†’ v{self.global_model_wrapper.version} ë‹¤ìš´ë¡œë“œ"
                    )
                    continue

                # â”€â”€ FedAsync â”€â”€
                if self.strategy == "fedasync":
                    self._fedasync_aggregate(sat_id, current_local_wrapper, temp_model, event_time)

                # â”€â”€ FedBuff â”€â”€
                elif self.strategy == "fedbuff":
                    self._fedbuff_collect(sat_id, current_local_wrapper, event_time)
                    is_last = (i == len(all_events) - 1)
                    if len(self.gs_buffer) >= FEDBUFF_K or is_last:
                        self._fedbuff_flush(temp_model, force_eval=is_last)

                # â”€â”€ FedSpace â”€â”€
                elif self.strategy == "fedspace":
                    self._fedbuff_collect(sat_id, current_local_wrapper, event_time)
                    is_last = (i == len(all_events) - 1)
                    if self._fedspace_should_flush(event_time, len(self.gs_buffer), is_last):
                        self._fedspace_aggregate(temp_model, force_eval=is_last)

                # â”€â”€ FedOrbit â”€â”€
                elif self.strategy == "fedorbit":
                    plane = self.get_plane_id(sat_id)
                    # ì£¼ì˜: IOT_TRAIN ì‹œ ì´ë¯¸ plane ë²„í¼ì— ìˆ˜ì§‘ë¨ (ì¤‘ë³µ ë°©ì§€)

                    # ë§ˆìŠ¤í„° ìœ„ì„±ì´ë©´ plane ì§‘ê³„ í›„ GS ì—…ë¡œë“œ
                    if self.plane_masters.get(plane) == sat_id:
                        self._fedorbit_master_upload(sat_id, current_local_wrapper, event_time, temp_model)
                    else:
                        # ë¹„ë§ˆìŠ¤í„° ìœ„ì„±: GS ì ‘ì´‰ ì‹œ ìµœì‹  ê¸€ë¡œë²Œ ë‹¤ìš´ë¡œë“œ
                        if self.global_model_wrapper.version > current_local_wrapper.version:
                            self.satellite_models[sat_id] = PyTorchModel.from_model(
                                self.global_model_net, version=self.global_model_wrapper.version
                            )
                            self.satellite_download_time[sat_id] = event_time
                            self.sim_logger.info(
                                f"   ğŸ“¥ SAT_{sat_id}: ê¸€ë¡œë²Œ v{self.global_model_wrapper.version} ë‹¤ìš´ë¡œë“œ"
                            )
                        self.satellite_last_trained_version[sat_id] = -1.0

        # ì”ì—¬ ë²„í¼ ì²˜ë¦¬
        if self.strategy in ("fedbuff", "fedspace") and len(self.gs_buffer) > 0:
            self._fedbuff_flush(temp_model, force_eval=True)

        # FedOrbit: ëª¨ë“  plane ì”ì—¬ ë²„í¼ ì²˜ë¦¬
        if self.strategy == "fedorbit":
            for plane_id in range(1, NUM_PLANES + 1):
                if len(self.plane_buffers[plane_id]) > 0:
                    self.last_intra_agg_time[plane_id] = self.start_time
                    result = self._fedorbit_try_intra_aggregate(plane_id, self.end_time, temp_model)
                    if result:
                        self.aggregation_round += 1
                        nv = round(self.global_model_wrapper.version + 1.0, 1)
                        global_sd = self.global_model_wrapper.model_state_dict
                        Î·_g = FEDORBIT_SERVER_LR
                        new_sd = OrderedDict()
                        for key in global_sd.keys():
                            if not self._is_gradient_param(key, global_sd[key]):
                                new_sd[key] = global_sd[key].clone()
                                continue
                            delta = global_sd[key].float() - result["state_dict"][key].float()
                            new_sd[key] = (global_sd[key].float() - Î·_g * delta).to(global_sd[key].dtype).cpu()
                        self._update_global_and_evaluate(
                            new_sd, nv, result["participants"], temp_model, force_eval=True
                        )

        self.sim_logger.info(f"\n=== ì‹œë®¬ë ˆì´ì…˜ ì¢…ë£Œ [{self.strategy.upper()}] ===")
        self.sim_logger.info(f"Total Aggregation Rounds: {self.aggregation_round}")
        self.sim_logger.info(f"Final Global Model Accuracy: {self.best_acc:.2f}%")


def main():
    try:
        start_time = datetime.now(timezone.utc)
        sim_logger, perf_logger = setup_loggers()
        sat_manager = Satellite_Manager(
            start_time, start_time + timedelta(days=30), sim_logger, perf_logger
        )
        asyncio.run(sat_manager.run())
    except KeyboardInterrupt:
        print("\nì‹œë®¬ë ˆì´ì…˜ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
    except Exception as e:
        print(f"Error: {e}")


if __name__ == "__main__":
    main()