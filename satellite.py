# object/satellite.py
# ============================================================
# LEO ìœ„ì„± ë¹„ë™ê¸° ì—°í•©í•™ìŠµ ë¹„êµ ì‹¤í—˜
# 570km Walker-Delta: 17 planes Ã— 14 sats = 238 satellites
#
# 4ê°œ ì „ëµ ë¹„êµ (config.py AGGREGATION_STRATEGYë¡œ ì „í™˜):
#   1. FedAsync  - 1:1 ì¦‰ì‹œ ë¹„ë™ê¸° (Xie et al., 2019)
#   2. FedBuff   - K-ë²„í¼ pseudo-gradient averaging (Nguyen et al., 2022)
#   3. FedSpace  - ê¶¤ë„ ì¸ì‹ ë™ì  ìŠ¤ì¼€ì¤„ë§ (So et al., 2022)
#   4. FedOrbit  - Plane í´ëŸ¬ìŠ¤í„° + ë§ˆìŠ¤í„° ìœ„ì„± (Jabbarpour et al., 2024)
#
# ê³µí†µ ê°œì„ ì‚¬í•­:
#   - ë¯¸í•™ìŠµ ìœ„ì„± í•„í„°ë§
#   - Cosine Annealing LR
#   - LOCAL_TRAIN í›„ í‰ê°€ ì œê±°
#   - GLOBAL_TEST í‰ê°€ ì£¼ê¸° ì¡°ì ˆ
# ============================================================

import asyncio
import torch
import numpy as np
import math
import random
from datetime import datetime, timedelta, timezone
from utils.skyfield_utils import EarthSatellite
from utils.logging_setup import setup_loggers, KST
from typing import Dict, List, Optional, Tuple
from pathlib import Path
from torch.utils.data import DataLoader
from collections import defaultdict, OrderedDict
from skyfield.api import load, wgs84

from config import (
    IOT_FLYOVER_THRESHOLD_DEG, GS_FLYOVER_THRESHOLD_DEG, LOCAL_EPOCHS,
    AGGREGATION_STRATEGY, NUM_PLANES, SATS_PER_PLANE, ORBIT_PERIOD_SEC,
    # FedAsync
    FEDASYNC_STALENESS_FUNC, FEDASYNC_ALPHA_MAX,
    # FedBuff
    FEDBUFF_K, FEDBUFF_SERVER_LR, FEDBUFF_SERVER_MOMENTUM,
    # FedSpace
    FEDSPACE_PREDICT_WINDOW_SEC, FEDSPACE_MIN_BUFFER, FEDSPACE_STALENESS_WEIGHT, FEDSPACE_SERVER_MOMENTUM,
    # FedOrbit
    FEDORBIT_INTRA_AGG_INTERVAL_SEC, FEDORBIT_SERVER_LR,
    # Common
    BASE_LR, MIN_LR, EVAL_EVERY_N_ROUNDS, STALENESS_THRESHOLD,
    NUM_CLIENTS, DIRICHLET_ALPHA, BATCH_SIZE, SAMPLES_PER_CLIENT,
    # Simulation time
    SIM_START_TIME, SIM_DURATION_DAYS,
)

from ml.data import get_cifar10_loaders
from ml.model import create_resnet9, PyTorchModel
from ml.training import train_model
from ml.aggregation import weighted_update
from ml.metrics import MetricsCollector

SEED = 42

class Satellite_Manager:
    """
    ìœ„ì„± ì—°í•©í•™ìŠµ ì‹œë®¬ë ˆì´ì…˜ ë§¤ë‹ˆì €.
    570km Walker-Delta (17Ã—14) constellationì—ì„œ
    FedAsync / FedBuff / FedSpace / FedOrbit 4ê°€ì§€ ì „ëµì„ ë¹„êµ ì‹¤í—˜í•©ë‹ˆë‹¤.
    """

    def __init__(self, start_time: datetime, end_time: datetime, sim_logger, perf_logger):
        self.start_time = start_time
        self.end_time = end_time
        self.sim_logger = sim_logger
        self.perf_logger = perf_logger

        self.satellites: Dict[int, EarthSatellite] = {}
        self.satellite_models: Dict[int, PyTorchModel] = {}
        self.satellite_performances: Dict[int, float] = {}
        self.satellite_last_trained_version: Dict[int, float] = {}

        # ìœ„ì„±ë³„ ê¸€ë¡œë²Œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹œì  ê¸°ë¡ (ì‹œê°„ ê¸°ë°˜ stalenessìš©)
        self.satellite_download_time: Dict[int, datetime] = {}

        self.check_arr = defaultdict(list)

        # --- FL ì„¤ì • ---
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        self.num_satellites = NUM_CLIENTS
        self.NUM_CLASSES = 10
        self.strategy = AGGREGATION_STRATEGY

        # --- Aggregation ìƒíƒœ ---
        self.aggregation_round = 0
        self.total_rounds = 0

        # FedBuff: pseudo-gradient ë²„í¼ + ì„œë²„ ëª¨ë©˜í…€
        self.gs_buffer: List[dict] = []
        self.server_momentum_state: Optional[OrderedDict] = None

        # FedSpace: ì ‘ì´‰ ì˜ˆì¸¡ ìºì‹œ
        self.gs_contact_schedule: List[dict] = []

        # FedOrbit: plane í´ëŸ¬ìŠ¤í„° ìƒíƒœ
        self.plane_buffers: Dict[int, List[dict]] = defaultdict(list)
        self.plane_masters: Dict[int, int] = {}
        self.last_intra_agg_time: Dict[int, datetime] = {}

        self.sim_logger.info(f"Strategy: {self.strategy.upper()}")
        self.sim_logger.info("CIFAR-10 ë°ì´í„°ì…‹ ë¡œë“œ ë° ìƒ˜í”Œë§ ì¤‘...")

        self.avg_data_count, self.client_subsets, self.val_loader, _ = get_cifar10_loaders(
            num_clients=self.num_satellites,
            dirichlet_alpha=DIRICHLET_ALPHA,
            data_root='./data',
            samples_per_client=SAMPLES_PER_CLIENT
        )
        self.sim_logger.info(f"ë°ì´í„°ì…‹ ë¡œë“œ ì™„ë£Œ. ìœ„ì„±ë‹¹ ë°ì´í„°: {self.avg_data_count:.0f}ì¥")

        self.global_model_net = create_resnet9(num_classes=self.NUM_CLASSES)
        self.global_model_net.to('cpu')
        self.global_model_wrapper = PyTorchModel.from_model(self.global_model_net, version=0.0)
        self.best_acc = 0.0

        # --- ì„±ëŠ¥ ì§€í‘œ ìˆ˜ì§‘ê¸° ---
        self.metrics = MetricsCollector(
            strategy=self.strategy,
            num_planes=NUM_PLANES,
            sats_per_plane=SATS_PER_PLANE,
            sim_start_time=self.start_time,
        )

        self.sim_logger.info("ìœ„ì„± ê´€ë¦¬ì ìƒì„± ì™„ë£Œ.")

    # ================================================================
    # Walker-Delta Constellation ìœ í‹¸ë¦¬í‹°
    # ================================================================

    @staticmethod
    def get_plane_id(sat_id: int) -> int:
        """TLE ìˆœë²ˆ ê¸°ë°˜: sat_idë¥¼ SATS_PER_PLANE(14)ìœ¼ë¡œ ë‚˜ëˆ  plane ê²°ì •.
        sat_id 0~13 â†’ plane 0, 14~27 â†’ plane 1, ..., 224~237 â†’ plane 16"""
        return sat_id // SATS_PER_PLANE

    @staticmethod
    def get_position_in_plane(sat_id: int) -> int:
        """plane ë‚´ ìœ„ì¹˜ (0~13)"""
        return sat_id % SATS_PER_PLANE

    def get_plane_satellites(self, plane_id: int) -> List[int]:
        """íŠ¹ì • planeì— ì†í•˜ëŠ” ëª¨ë“  ìœ„ì„± ID ë°˜í™˜"""
        return [sid for sid in self.satellites.keys() if sid // SATS_PER_PLANE == plane_id]

    # ================================================================
    # ê¶¤ë„/í†µì‹  ìŠ¤ì¼€ì¤„ (ëª¨ë“  ì „ëµ ê³µí†µ)
    # ================================================================

    def load_constellation(self):
        tle_path = "constellation.tle"
        satellites = {}
        try:
            with open(tle_path, "r") as f:
                lines = [line.strip() for line in f.readlines()]
                i = 0
                while i < len(lines):
                    if not lines[i]:
                        i += 1
                        continue
                    name, line1, line2 = lines[i:i + 3]
                    sat_id = int(name.replace("SAT", "").replace("_", ""))
                    satellites[sat_id] = EarthSatellite(line1, line2, name)
                    i += 3
            self.satellites = satellites
            self.sim_logger.info(
                f"Constellation ë¡œë“œ: {len(satellites)}ê°œ ìœ„ì„±, "
                f"{NUM_PLANES} planes Ã— {SATS_PER_PLANE} sats"
            )
        except Exception as e:
            self.sim_logger.error(f"TLE íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise e

    async def run(self):
        self.sim_logger.info("ìœ„ì„± ê´€ë¦¬ì ìš´ì˜ ì‹œì‘.")
        self.load_constellation()

        for sat_id in self.satellites.keys():
            self.satellite_models[sat_id] = PyTorchModel.from_model(self.global_model_net, version=0.0)
            self.satellite_performances[sat_id] = 0.0
            self.satellite_last_trained_version[sat_id] = -1.0
            self.satellite_download_time[sat_id] = self.start_time

        await self.propagate_orbit(self.start_time, self.end_time)
        self.sim_logger.info(f"ê¶¤ë„ ì „íŒŒ ì™„ë£Œ ({len(self.times)} steps).")

        await self.check_iot_comm()
        await self.check_gs_comm()
        self.sim_logger.info("ëª¨ë“  í†µì‹  ìŠ¤ì¼€ì¤„ ê³„ì‚° ì™„ë£Œ.")

        if self.strategy == "fedorbit":
            self._fedorbit_init_masters()

        await self.manage_fl_process()
        self.sim_logger.info("ëª¨ë“  ì‹œë®¬ë ˆì´ì…˜ ì¢…ë£Œ.")

    async def propagate_orbit(self, start_time, end_time):
        step = timedelta(seconds=10)
        self.times = []
        curr = start_time
        while curr < end_time:
            self.times.append(curr)
            curr += step
        ts = load.timescale()
        self.t_vector = ts.from_datetimes(self.times)

    async def check_iot_comm(self):
        self.sim_logger.info("IoT í†µì‹  ê°€ëŠ¥ ì‹œê°„ ë¶„ì„ ì‹œì‘...")
        iot_devices = [
            {"name": "Amazon_Forest", "loc": wgs84.latlon(-3.47, -62.37, elevation_m=100)},
            {"name": "Great_Barrier_Reef", "loc": wgs84.latlon(-18.29, 147.77, elevation_m=0)},
            {"name": "Abisko Tundra", "loc": wgs84.latlon(68.35, 18.79, elevation_m=420)},
        ]
        for iot in iot_devices:
            for sat_id, satellite in self.satellites.items():
                difference = satellite - iot['loc']
                topocentric = difference.at(self.t_vector)
                alt, _, _ = topocentric.altaz()
                visible_indices = np.where(alt.degrees > IOT_FLYOVER_THRESHOLD_DEG)[0]
                if len(visible_indices) == 0:
                    continue
                breaks = np.where(np.diff(visible_indices) > 1)[0] + 1
                windows = np.split(visible_indices, breaks)
                for window in windows:
                    st = self.times[window[0]]
                    et = self.times[window[-1]]
                    dur = (et - st).total_seconds()
                    if dur == 0:
                        dur = 10
                    self.check_arr[sat_id].append({
                        "type": "IOT_TRAIN", "start_time": st, "end_time": et,
                        "duration": dur, "target": iot['name']
                    })

    async def check_gs_comm(self):
        self.sim_logger.info("ì§€ìƒêµ­ í†µì‹  ê°€ëŠ¥ ì‹œê°„ ë¶„ì„ ì‹œì‘...")
        gs = {"name": "Ground Station", "loc": wgs84.latlon(37.5665, 126.9780, elevation_m=34)}
        for sat_id, satellite in self.satellites.items():
            difference = satellite - gs['loc']
            topocentric = difference.at(self.t_vector)
            alt, _, _ = topocentric.altaz()
            visible_indices = np.where(alt.degrees > GS_FLYOVER_THRESHOLD_DEG)[0]
            if len(visible_indices) == 0:
                continue
            breaks = np.where(np.diff(visible_indices) > 1)[0] + 1
            windows = np.split(visible_indices, breaks)
            for window in windows:
                st = self.times[window[0]]
                et = self.times[window[-1]]
                dur = (et - st).total_seconds()
                if dur == 0:
                    dur = 10
                self.check_arr[sat_id].append({
                    "type": "GS_AGGREGATE", "start_time": st, "end_time": et,
                    "duration": dur, "target": gs['name']
                })

    # ================================================================
    # ê³µí†µ ìœ í‹¸ë¦¬í‹°
    # ================================================================

    def _get_cosine_lr(self) -> float:
        """Cosine Annealing LR: BASE_LR â†’ MIN_LR"""
        progress = min(self.aggregation_round / max(self.total_rounds, 1), 1.0)
        return MIN_LR + 0.5 * (BASE_LR - MIN_LR) * (1 + math.cos(math.pi * progress))

    def _evaluate_direct(self, model, data_loader, sat_id, version, stage):
        model.to(self.device)
        model.eval()
        criterion = torch.nn.CrossEntropyLoss()
        correct, total, total_loss = 0, 0, 0.0
        with torch.no_grad():
            for images, labels in data_loader:
                images, labels = images.to(self.device), labels.to(self.device)
                outputs = model(images)
                loss = criterion(outputs, labels)
                total_loss += loss.item()
                _, predicted = torch.max(outputs.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()
        acc = 100 * correct / total
        avg_loss = total_loss / len(data_loader) if len(data_loader) > 0 else 0
        self.perf_logger.info(
            f"{datetime.now(KST).isoformat()},{stage},{sat_id},{version:.2f},"
            f"{self.strategy},{acc:.4f},{avg_loss:.6f},0.0000"
        )
        model.to('cpu')
        return acc, avg_loss

    def _is_trained_since_global(self, sat_id) -> bool:
        return self.satellite_last_trained_version[sat_id] > 0

    @staticmethod
    def _is_gradient_param(key: str, tensor: torch.Tensor) -> bool:
        """pseudo-gradient ì—°ì‚° ëŒ€ìƒì¸ì§€ íŒë³„.
        BatchNormì˜ num_batches_tracked(int64) ë“± non-float í…ì„œëŠ” ì œì™¸."""
        return tensor.is_floating_point()

    def _staleness_function(self, staleness: float) -> float:
        """s(Ï„) = 1/(1+Ï„)^0.5 â€” FedAsync/FedBuff ê³µí†µ"""
        if FEDASYNC_STALENESS_FUNC == "poly":
            return (1.0 + staleness) ** (-0.5)
        elif FEDASYNC_STALENESS_FUNC == "hinge":
            return 1.0 if staleness <= STALENESS_THRESHOLD else 0.0
        else:
            return 1.0

    def _compute_staleness(self, local_wrapper, event_time: datetime) -> Tuple[float, float]:
        """ë²„ì „ ê¸°ë°˜ staleness ê³„ì‚°.
        Returns: (Ï„_version, Ï„_time_normalized)"""
        tau_ver = max(0, self.global_model_wrapper.version - int(local_wrapper.version))
        return tau_ver, 0.0

    def _update_global_and_evaluate(self, new_state_dict, new_version,
                                     participating_ids, temp_model, force_eval=False,
                                     staleness_values=None, sim_time=None,
                                     plane_id=None):
        """ê¸€ë¡œë²Œ ëª¨ë¸ ì—…ë°ì´íŠ¸ + í‰ê°€ + ì²´í¬í¬ì¸íŠ¸ + ë©”íŠ¸ë¦­ ê¸°ë¡ (ê³µí†µ)"""
        self.global_model_net.load_state_dict(new_state_dict)

        g_acc, g_loss = None, None
        if force_eval or (self.aggregation_round % EVAL_EVERY_N_ROUNDS == 0):
            temp_model.load_state_dict(new_state_dict)
            g_acc, g_loss = self._evaluate_direct(
                temp_model, self.val_loader, sat_id="GS",
                version=new_version, stage="GLOBAL_TEST"
            )
            if g_acc > self.best_acc:
                prev = self.best_acc
                self.best_acc = g_acc
                save_dir = Path("./checkpoints")
                save_dir.mkdir(parents=True, exist_ok=True)
                torch.save({
                    'model_state_dict': new_state_dict,
                    'version': new_version,
                    'accuracy': g_acc, 'loss': g_loss,
                    'round': self.aggregation_round,
                    'strategy': self.strategy,
                    'participants': participating_ids,
                }, save_dir / f"{self.strategy}_v{int(new_version)}_acc{g_acc:.2f}.pth")
                self.sim_logger.info(f"   ğŸ’¾ New Best! ({prev:.2f}% â†’ {g_acc:.2f}%)")
            self.sim_logger.info(
                f"   ğŸ“Š Round #{self.aggregation_round}: v{new_version:.0f} Acc: {g_acc:.2f}%"
            )
        else:
            self.sim_logger.info(
                f"   ğŸ“Š Round #{self.aggregation_round}: v{new_version:.0f} (í‰ê°€ ìŠ¤í‚µ)"
            )

        self.global_model_wrapper = PyTorchModel(
            version=new_version,
            model_state_dict=new_state_dict,
            trained_by=self.global_model_wrapper.trained_by + participating_ids
        )

        self.metrics.record_aggregation(
            round_num=self.aggregation_round,
            sim_time=sim_time or self.start_time,
            accuracy=g_acc,
            loss=g_loss,
            participating_ids=participating_ids,
            staleness_values=staleness_values or [],
            plane_id=plane_id,
        )

    # ================================================================
    # Strategy 1: FedAsync (Xie et al., 2019)
    #
    # GS ì ‘ì´‰ ì¦‰ì‹œ 1:1 ê°€ì¤‘ í‰ê·  (ë…¼ë¬¸ Algorithm 1):
    #   Î±_t = Î± Ã— s(Ï„),  s(Ï„) = (1+Ï„)^{-0.5}
    #   x_t = (1 - Î±_t) * x_global + Î±_t * x_local
    # ================================================================

    def _fedasync_aggregate(self, sat_id, local_wrapper, temp_model, event_time):
        self.aggregation_round += 1
        new_version = round(self.global_model_wrapper.version + 1.0, 1)

        tau_ver, _ = self._compute_staleness(local_wrapper, event_time)
        s_tau = self._staleness_function(tau_ver)

        alpha_eff = FEDASYNC_ALPHA_MAX * s_tau

        self.sim_logger.info(
            f"   âš¡ [FedAsync] Î±={FEDASYNC_ALPHA_MAX}Ã—s(Ï„={tau_ver})={s_tau:.3f} â†’ Î±_eff={alpha_eff:.4f}"
        )

        new_sd = weighted_update(
            self.global_model_wrapper.model_state_dict,
            local_wrapper.model_state_dict, alpha_eff
        )
        self._update_global_and_evaluate(
            new_sd, new_version, [sat_id], temp_model,
            staleness_values=[tau_ver], sim_time=event_time,
        )

        self.metrics.record_gs_contact(sat_id, event_time, "upload")

        self.satellite_models[sat_id] = PyTorchModel.from_model(
            self.global_model_net, version=new_version
        )
        self.satellite_last_trained_version[sat_id] = -1.0
        self.satellite_download_time[sat_id] = event_time

    # ================================================================
    # Strategy 2: FedBuff (Nguyen et al., 2022) â€” Satellite-Adapted
    #
    # ì›ë³¸: pseudo-gradient SGD (Î·_â„“=0.0002, Î·_g=40.9, datacenter)
    # ì ì‘: staleness-weighted buffered averaging (ìœ„ì„± ê³ ì§€ì—° í™˜ê²½)
    #
    #   Î”_avg = Î£ (s_i/Î£s) Ã— (global_current - trained_i)
    #   m_t = Î²Â·m_{t-1} + Î”_avg          (ì„œë²„ ëª¨ë©˜í…€)
    #   x_{t+1} = x_t - Î·_g Â· m_t
    #
    # Î·_g=1.0ì—ì„œ (Î²=0 ê°€ì •): new = Î£ (s_i/Î£s) Ã— trained_i (convex combination)
    # ================================================================

    def _fedbuff_collect(self, sat_id, local_wrapper, event_time):
        """ë²„í¼ì— í•™ìŠµ ì™„ë£Œ ëª¨ë¸ ìˆ˜ì§‘.
        s(Ï„)ëŠ” flush ì‹œ ì •ê·œí™” ê°€ì¤‘ì¹˜ë¡œ ì‚¬ìš© (stale ìœ„ì„± ê¸°ì—¬ ê°ì†Œ)."""
        tau_ver, _ = self._compute_staleness(local_wrapper, event_time)
        s_tau = self._staleness_function(tau_ver)
        loader_idx = sat_id % len(self.client_subsets)

        self.gs_buffer.append({
            "sat_id": sat_id,
            "state_dict": local_wrapper.model_state_dict,
            "base_version": int(local_wrapper.version),
            "staleness": tau_ver,
            "s_tau": s_tau,
            "data_count": len(self.client_subsets[loader_idx]),
            "event_time": event_time,
        })
        self.sim_logger.info(
            f"   ğŸ“¦ ë²„í¼ ì¶”ê°€ (v{local_wrapper.version:.1f}, "
            f"Ï„={tau_ver}, ë²„í¼: {len(self.gs_buffer)}/{FEDBUFF_K})"
        )

    def _fedbuff_flush(self, temp_model, force_eval=False):
        """Satellite-adapted FedBuff: staleness-weighted buffered averaging.

        ìœ„ì„± í™˜ê²½ ì ì‘:
          ë…¼ë¬¸(Nguyen et al., 2022)ì€ base_i - trained_i (pseudo-gradient SGD)ë¥¼ ì‚¬ìš©í•˜ì§€ë§Œ,
          ìœ„ì„± í™˜ê²½ì˜ êµ¬ì¡°ì  ê³ ì§€ì—°(mean Ï„â‰ˆ15)ì—ì„œëŠ” base_i â‰  global_currentë¡œ ì¸í•´
          stale pseudo-gradient driftê°€ ë°œìƒí•˜ì—¬ ë°œì‚°í•¨.

          global_current ê¸°ì¤€ + s(Ï„) ì •ê·œí™” ê°€ì¤‘í•©ìœ¼ë¡œ ë³€ê²½í•˜ë©´:
            Î”_avg = Î£ (s_i/Î£s) Ã— (global_current - trained_i)
            new = global - Î·_g Ã— Î”_avg
          Î·_g=1.0ì¼ ë•Œ: new = Î£ (s_i/Î£s) Ã— trained_i â†’ convex combination â†’ ìˆ˜ë ´ ì•ˆì •ì„± ë³´ì¥.
        """
        if len(self.gs_buffer) == 0:
            return

        self.aggregation_round += 1
        new_version = round(self.global_model_wrapper.version + 1.0, 1)
        K = len(self.gs_buffer)
        participating_ids = [m["sat_id"] for m in self.gs_buffer]

        self.sim_logger.info(
            f"\nâš¡ [FedBuff Round #{self.aggregation_round}] K={K}: {participating_ids}"
        )

        global_sd = self.global_model_wrapper.model_state_dict

        # Satellite-adapted: Î”_avg = Î£ (s_i/Î£s) Ã— (global_current - trained_i)
        # s(Ï„) ì •ê·œí™” â†’ stale ìœ„ì„± ê¸°ì—¬ ìë™ ê°ì†Œ, Î·_g=1.0ì—ì„œ convex combination
        total_s = sum(m["s_tau"] for m in self.gs_buffer)
        if total_s == 0:
            total_s = float(K)

        delta_avg = OrderedDict()
        for key in global_sd.keys():
            if not self._is_gradient_param(key, global_sd[key]):
                delta_avg[key] = None
                continue
            delta = torch.zeros_like(global_sd[key], dtype=torch.float32)
            for m in self.gs_buffer:
                pseudo_grad = global_sd[key].float() - m["state_dict"][key].float()
                delta += (m["s_tau"] / total_s) * pseudo_grad
            delta_avg[key] = delta

        # ì„œë²„ ëª¨ë©˜í…€: m_t = Î²Â·m_{t-1} + Î”_avg
        if self.strategy == "fedbuff":
            beta = FEDBUFF_SERVER_MOMENTUM
        elif self.strategy == "fedspace":
            beta = FEDSPACE_SERVER_MOMENTUM
            
        if self.server_momentum_state is None:
            self.server_momentum_state = OrderedDict()
            for key in delta_avg:
                if delta_avg[key] is not None:
                    self.server_momentum_state[key] = delta_avg[key].clone()
        else:
            for key in delta_avg:
                if delta_avg[key] is not None and key in self.server_momentum_state:
                    self.server_momentum_state[key] = (
                        beta * self.server_momentum_state[key] + delta_avg[key]
                    )

        # w_{t+1} = w_t - Î·_g Â· m_t
        eta_g = FEDBUFF_SERVER_LR
        new_sd = OrderedDict()
        for key in global_sd.keys():
            if not self._is_gradient_param(key, global_sd[key]):
                new_sd[key] = global_sd[key].clone()
            elif key in self.server_momentum_state:
                new_sd[key] = (
                    global_sd[key].float() - eta_g * self.server_momentum_state[key]
                ).to(global_sd[key].dtype).cpu()
            else:
                new_sd[key] = global_sd[key].clone()

        self.sim_logger.info(f"   ğŸ“ Î·_g={eta_g}, Î²={beta}, K={K}")

        staleness_vals = [m["staleness"] for m in self.gs_buffer]
        sim_time = self.gs_buffer[-1]["event_time"]

        self._update_global_and_evaluate(
            new_sd, new_version, participating_ids, temp_model, force_eval,
            staleness_values=staleness_vals, sim_time=sim_time,
        )

        for m in self.gs_buffer:
            self.metrics.record_gs_contact(m["sat_id"], sim_time, "upload")

        # ì°¸ì—¬ ìœ„ì„± ë™ê¸°í™”
        for m in self.gs_buffer:
            self.satellite_models[m["sat_id"]] = PyTorchModel.from_model(
                self.global_model_net, version=new_version
            )
            self.satellite_last_trained_version[m["sat_id"]] = -1.0

        self.gs_buffer = []

    # ================================================================
    # Strategy 3: FedSpace (So et al., 2022)
    #
    # í•µì‹¬: ê¶¤ë„ ì˜ˆì¸¡ìœ¼ë¡œ GS ì ‘ì´‰ ë°€ë„ë¥¼ íŒŒì•… â†’
    #       staleness-idleness trade-offë¥¼ ë™ì ìœ¼ë¡œ ìµœì í™”í•˜ì—¬ ì§‘ê³„ ì‹œì  ê²°ì •.
    # ================================================================

    def _fedspace_predict_upcoming_contacts(self, current_time, window_sec=None) -> int:
        """í–¥í›„ window_sec ë‚´ ì˜ˆìƒ GS ì ‘ì´‰ ìˆ˜"""
        if window_sec is None:
            window_sec = FEDSPACE_PREDICT_WINDOW_SEC
        deadline = current_time + timedelta(seconds=window_sec)
        count = 0
        for evt in self.gs_contact_schedule:
            if evt["start_time"] > deadline:
                break
            if evt["start_time"] > current_time:
                count += 1
        return count

    def _fedspace_should_flush(self, current_time, buffer_size, is_last=False) -> bool:
        """FedSpace ë™ì  flush íŒë‹¨"""
        if is_last or buffer_size <= 0:
            return is_last and buffer_size > 0

        upcoming = self._fedspace_predict_upcoming_contacts(current_time)
        w = FEDSPACE_STALENESS_WEIGHT

        # ì ‘ì´‰ ë§ìœ¼ë©´ threshold ë†’ì—¬ì„œ ë” ëª¨ìœ¼ê³ , ì ìœ¼ë©´ ë¹¨ë¦¬ ì§‘ê³„
        dynamic_threshold = max(
            FEDSPACE_MIN_BUFFER,
            int(FEDSPACE_MIN_BUFFER + w * min(upcoming, 15))
        )

        should = buffer_size >= dynamic_threshold
        if should:
            self.sim_logger.info(
                f"   ğŸŒ [FedSpace] ì§‘ê³„ ê²°ì •: ë²„í¼={buffer_size} â‰¥ "
                f"threshold={dynamic_threshold} (í–¥í›„ ì ‘ì´‰ {upcoming}ê°œ)"
            )
        return should

    def _fedspace_aggregate(self, temp_model, force_eval=False):
        """FedSpace: FedBuffì™€ ë™ì¼í•œ pseudo-gradient ë°©ì‹, ì‹œì ë§Œ ë‹¤ë¦„"""
        self._fedbuff_flush(temp_model, force_eval)

    # ================================================================
    # Strategy 4: FedOrbit (Jabbarpour et al., 2024)
    #
    # í•µì‹¬ êµ¬ì„±:
    #   1. Plane-based Clustering: 17ê°œ orbital plane = 17ê°œ í´ëŸ¬ìŠ¤í„°
    #   2. Master Satellite: plane ë‚´ GS ì ‘ì´‰ ë¹ˆë„ ìµœë‹¤ ìœ„ì„±
    #   3. Intra-Plane ISL Aggregation: plane ë‚´ FedAvg
    #   4. Master â†’ GS Upload: ë§ˆìŠ¤í„°ê°€ plane ëŒ€í‘œ ëª¨ë¸ì„ pseudo-gradientë¡œ ì „ì†¡
    # ================================================================

    def _fedorbit_init_masters(self):
        """ê° planeì—ì„œ GS ì ‘ì´‰ ë¹ˆë„ê°€ ê°€ì¥ ë†’ì€ ìœ„ì„±ì„ ë§ˆìŠ¤í„°ë¡œ ì„ ì •"""
        plane_gs_count = defaultdict(lambda: defaultdict(int))

        for sat_id, events in self.check_arr.items():
            plane = self.get_plane_id(sat_id)
            gs_contacts = sum(1 for e in events if e["type"] == "GS_AGGREGATE")
            plane_gs_count[plane][sat_id] = gs_contacts

        for plane_id in range(NUM_PLANES):
            if plane_id in plane_gs_count and plane_gs_count[plane_id]:
                master = max(plane_gs_count[plane_id], key=plane_gs_count[plane_id].get)
                self.plane_masters[plane_id] = master
                self.last_intra_agg_time[plane_id] = self.start_time
                self.sim_logger.info(
                    f"   ğŸ›°ï¸ Plane {plane_id}: Master=SAT_{master} "
                    f"(GSì ‘ì´‰ {plane_gs_count[plane_id][master]}íšŒ)"
                )

    def _fedorbit_intra_plane_collect(self, sat_id, local_wrapper, event_time):
        """
        Intra-Plane ISL ë²„í¼ì— ìˆ˜ì§‘.
        [ìˆ˜ì •] ìœ„ì„±ë‹¹ ìµœì‹  ëª¨ë¸ë§Œ ìœ ì§€ â€” ì¤‘ë³µ ì¶•ì  ë°©ì§€.
        ê°™ì€ ìœ„ì„±ì´ ì—¬ëŸ¬ ë²ˆ í•™ìŠµí•˜ë©´ ì´ì „ ì—”íŠ¸ë¦¬ë¥¼ êµì²´í•©ë‹ˆë‹¤.
        ë…¼ë¬¸ ì›ë³¸: ë¼ìš´ë“œë‹¹ ìœ„ì„±ë³„ 1ê°œ ëª¨ë¸ë§Œ ì§‘ê³„ ì°¸ì—¬.
        """
        plane_id = self.get_plane_id(sat_id)
        loader_idx = sat_id % len(self.client_subsets)

        new_entry = {
            "sat_id": sat_id,
            "state_dict": local_wrapper.model_state_dict,
            "version": local_wrapper.version,
            "data_count": len(self.client_subsets[loader_idx]),
        }

        # ê¸°ì¡´ ì—”íŠ¸ë¦¬ êµì²´ (ê°™ì€ ìœ„ì„± IDê°€ ìˆìœ¼ë©´ ìµœì‹ ìœ¼ë¡œ ë®ì–´ì“°ê¸°)
        buf = self.plane_buffers[plane_id]
        replaced = False
        for idx, entry in enumerate(buf):
            if entry["sat_id"] == sat_id:
                buf[idx] = new_entry
                replaced = True
                break

        if not replaced:
            buf.append(new_entry)

    def _fedorbit_try_intra_aggregate(self, plane_id, event_time, temp_model):
        """Plane ë‚´ ISL ì§‘ê³„: ì£¼ê¸°ì ìœ¼ë¡œ plane ë‚´ ëª¨ë¸ë“¤ì„ FedAvg"""
        buf = self.plane_buffers[plane_id]
        if len(buf) == 0:
            return None

        elapsed = (event_time - self.last_intra_agg_time.get(plane_id, self.start_time)).total_seconds()
        if elapsed < FEDORBIT_INTRA_AGG_INTERVAL_SEC and len(buf) < SATS_PER_PLANE:
            return None

        self.last_intra_agg_time[plane_id] = event_time

        total_data = sum(m["data_count"] for m in buf)
        if total_data == 0:
            total_data = len(buf)

        aggregated = OrderedDict()
        for key in buf[0]["state_dict"].keys():
            if not self._is_gradient_param(key, buf[0]["state_dict"][key]):
                aggregated[key] = buf[0]["state_dict"][key].clone()
                continue
            param = torch.zeros_like(buf[0]["state_dict"][key], dtype=torch.float32)
            for m in buf:
                w = m["data_count"] / total_data
                param += w * m["state_dict"][key].float()
            aggregated[key] = param.to(buf[0]["state_dict"][key].dtype).cpu()

        self.sim_logger.info(
            f"   ğŸ”— [FedOrbit ISL] Plane {plane_id}: "
            f"{len(buf)}ê°œ ìœ„ì„± intra-plane ì§‘ê³„ ì™„ë£Œ"
        )

        participating = [m["sat_id"] for m in buf]
        staleness_vals = [
            max(0, self.global_model_wrapper.version - int(m.get("version", 0)))
            for m in buf
        ]

        # ë²„í¼ í´ë¦¬ì–´ (staleness ê³„ì‚° í›„!)
        self.plane_buffers[plane_id] = []

        return {
            "state_dict": aggregated,
            "participants": participating,
            "plane_id": plane_id,
            "staleness_values": staleness_vals,
        }

    def _fedorbit_master_upload(self, sat_id, local_wrapper, event_time, temp_model):
        """ë§ˆìŠ¤í„° ìœ„ì„± GS ì ‘ì´‰: plane ISL ì§‘ê³„ â†’ pseudo-gradientë¡œ ê¸€ë¡œë²Œ ì—…ë°ì´íŠ¸"""
        plane_id = self.get_plane_id(sat_id)

        # Intra-plane ì§‘ê³„ ê°•ì œ ì‹¤í–‰
        self.last_intra_agg_time[plane_id] = self.start_time
        result = self._fedorbit_try_intra_aggregate(plane_id, event_time, temp_model)

        if result is None:
            return False

        self.aggregation_round += 1
        new_version = round(self.global_model_wrapper.version + 1.0, 1)

        global_sd = self.global_model_wrapper.model_state_dict
        plane_sd = result["state_dict"]

        # pseudo-gradient: Î” = global - plane_aggregated â†’ w_new = w - Î·Â·Î”
        eta_g = FEDORBIT_SERVER_LR
        new_sd = OrderedDict()
        for key in global_sd.keys():
            if not self._is_gradient_param(key, global_sd[key]):
                new_sd[key] = global_sd[key].clone()
                continue
            delta = global_sd[key].float() - plane_sd[key].float()
            new_sd[key] = (global_sd[key].float() - eta_g * delta).to(global_sd[key].dtype).cpu()

        self.sim_logger.info(
            f"   ğŸš€ [FedOrbit] Plane {plane_id} Master SAT_{sat_id} â†’ GS Upload "
            f"({len(result['participants'])}ê°œ ìœ„ì„±)"
        )

        self._update_global_and_evaluate(
            new_sd, new_version, result["participants"], temp_model,
            staleness_values=result.get("staleness_values", [0]), sim_time=event_time,
            plane_id=plane_id,
        )

        self.metrics.record_gs_contact(sat_id, event_time, "upload")

        # Plane ë‚´ ëª¨ë“  ìœ„ì„± ë™ê¸°í™”
        for sid in self.get_plane_satellites(plane_id):
            self.satellite_models[sid] = PyTorchModel.from_model(
                self.global_model_net, version=new_version
            )
            self.satellite_last_trained_version[sid] = -1.0
            self.satellite_download_time[sid] = event_time

        return True

    # ================================================================
    # ë©”ì¸ FL í”„ë¡œì„¸ìŠ¤
    # ================================================================

    async def manage_fl_process(self):
        self.sim_logger.info(
            f"\n=== ì—°í•© í•™ìŠµ ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘ [{self.strategy.upper()}] ==="
        )

        # ì „ì²´ ì´ë²¤íŠ¸ ì‹œê°„ìˆœ ì •ë ¬
        all_events = []
        for sat_id, events in self.check_arr.items():
            for event in events:
                event['sat_id'] = sat_id
                all_events.append(event)
        all_events.sort(key=lambda x: x['start_time'])

        # FedSpace: GS ì ‘ì´‰ ìŠ¤ì¼€ì¤„ ìºì‹±
        self.gs_contact_schedule = [e for e in all_events if e['type'] == 'GS_AGGREGATE']

        # ì „ëµë³„ ì˜ˆìƒ ì´ ë¼ìš´ë“œ ìˆ˜ (Cosine LR ìŠ¤ì¼€ì¤„ë§ìš©)
        gs_event_count = len(self.gs_contact_schedule)
        iot_event_count = len(all_events) - gs_event_count
        if self.strategy == "fedasync":
            self.total_rounds = max(gs_event_count, 1)
        elif self.strategy == "fedbuff":
            self.total_rounds = max(gs_event_count // FEDBUFF_K, 1)
        elif self.strategy == "fedspace":
            self.total_rounds = max(gs_event_count // FEDSPACE_MIN_BUFFER, 1)
        elif self.strategy == "fedorbit":
            self.total_rounds = max(gs_event_count // max(NUM_PLANES, 1), 1)
        else:
            self.total_rounds = max(gs_event_count, 1)

        self.sim_logger.info(
            f"ğŸ“… ì´ {len(all_events)}ê°œ ì´ë²¤íŠ¸ "
            f"(IOT: {iot_event_count}, GS: {gs_event_count}) | "
            f"ì˜ˆìƒ ë¼ìš´ë“œ: {self.total_rounds} | Strategy: {self.strategy}"
        )

        temp_model = create_resnet9(num_classes=self.NUM_CLASSES)

        for i, event in enumerate(all_events):
            sat_id = event['sat_id']
            current_local_wrapper = self.satellite_models[sat_id]
            event_time = event['start_time']

            # â”€â”€â”€ IOT_TRAIN (ê³µí†µ) â”€â”€â”€
            if event['type'] == 'IOT_TRAIN':
                self.sim_logger.info(
                    f"\nğŸ“¡ [{event_time.strftime('%m-%d %H:%M')}] "
                    f"SAT_{sat_id} : IoT í•™ìŠµ ({event['target']})"
                )

                loader_idx = sat_id % len(self.client_subsets)
                dataset = self.client_subsets[loader_idx]

                def seed_worker(worker_id):
                    worker_seed = torch.initial_seed() % 2**32
                    np.random.seed(worker_seed)
                    random.seed(worker_seed)

                train_loader = DataLoader(
                    dataset, batch_size=BATCH_SIZE, shuffle=True,
                    num_workers=8, pin_memory=True,
                    worker_init_fn=seed_worker,
                    generator=torch.Generator().manual_seed(SEED)
                )

                current_local_wrapper.to_device(temp_model, device='cpu')
                current_lr = self._get_cosine_lr()

                train_model(
                    model=temp_model,
                    global_state_dict=self.global_model_wrapper.model_state_dict,
                    train_loader=train_loader,
                    epochs=LOCAL_EPOCHS, lr=current_lr,
                    device=self.device, sim_logger=self.sim_logger
                )

                next_version = round(current_local_wrapper.version + 0.1, 1)
                current_local_wrapper = PyTorchModel.from_model(temp_model, version=next_version)
                self.satellite_models[sat_id] = current_local_wrapper
                self.satellite_last_trained_version[sat_id] = next_version

                self.sim_logger.info(
                    f"   âœ… SAT_{sat_id} í•™ìŠµ ì™„ë£Œ (LR: {current_lr:.4f}, v{next_version:.1f})"
                )

                self.metrics.record_train(sat_id, self.get_plane_id(sat_id), event_time)

                # FedOrbit: í•™ìŠµ ì™„ë£Œ ì‹œ plane ë²„í¼ì— ìë™ ìˆ˜ì§‘
                if self.strategy == "fedorbit":
                    self._fedorbit_intra_plane_collect(sat_id, current_local_wrapper, event_time)

            # â”€â”€â”€ GS_AGGREGATE (ì „ëµ ë¶„ê¸°) â”€â”€â”€
            elif event['type'] == 'GS_AGGREGATE':
                self.sim_logger.info(
                    f"\nğŸ“¡ [{event_time.strftime('%m-%d %H:%M')}] "
                    f"SAT_{sat_id} : ì§€ìƒêµ­ ì ‘ì†"
                )

                # [ê³µí†µ] ë¯¸í•™ìŠµ ìœ„ì„± í•„í„°ë§
                if not self._is_trained_since_global(sat_id):
                    if self.global_model_wrapper.version > current_local_wrapper.version:
                        self.satellite_models[sat_id] = PyTorchModel.from_model(
                            self.global_model_net, version=self.global_model_wrapper.version
                        )
                        self.satellite_download_time[sat_id] = event_time
                        self.metrics.record_gs_contact(sat_id, event_time, "download")
                        self.sim_logger.info(
                            f"   ğŸ“¥ SAT_{sat_id}: ë¯¸í•™ìŠµ â†’ v{self.global_model_wrapper.version} ë‹¤ìš´ë¡œë“œ"
                        )
                    else:
                        self.metrics.record_gs_contact(sat_id, event_time, "skip")
                        self.sim_logger.info(f"   â­ï¸ SAT_{sat_id}: ë¯¸í•™ìŠµ & ìµœì‹  â†’ Skip")

                    # FedOrbit: ë§ˆìŠ¤í„°ì¸ ê²½ìš° plane ë²„í¼ê°€ ìˆìœ¼ë©´ ì—…ë¡œë“œ ì‹œë„
                    if self.strategy == "fedorbit":
                        plane = self.get_plane_id(sat_id)
                        if self.plane_masters.get(plane) == sat_id and len(self.plane_buffers[plane]) > 0:
                            self._fedorbit_master_upload(sat_id, current_local_wrapper, event_time, temp_model)
                    continue

                # [ê³µí†µ] Staleness ì´ˆê³¼ â†’ ë‹¤ìš´ë¡œë“œë§Œ
                if self.global_model_wrapper.version > current_local_wrapper.version + STALENESS_THRESHOLD:
                    self.satellite_models[sat_id] = PyTorchModel.from_model(
                        self.global_model_net, version=self.global_model_wrapper.version
                    )
                    self.satellite_last_trained_version[sat_id] = -1.0
                    self.satellite_download_time[sat_id] = event_time
                    self.metrics.record_gs_contact(sat_id, event_time, "download")
                    self.sim_logger.info(
                        f"   ğŸ“¥ SAT_{sat_id}: Stale â†’ v{self.global_model_wrapper.version} ë‹¤ìš´ë¡œë“œ"
                    )
                    continue

                # â”€â”€ FedAsync â”€â”€
                if self.strategy == "fedasync":
                    self._fedasync_aggregate(sat_id, current_local_wrapper, temp_model, event_time)

                # â”€â”€ FedBuff â”€â”€
                elif self.strategy == "fedbuff":
                    self._fedbuff_collect(sat_id, current_local_wrapper, event_time)
                    is_last = (i == len(all_events) - 1)
                    if len(self.gs_buffer) >= FEDBUFF_K or is_last:
                        self._fedbuff_flush(temp_model, force_eval=is_last)

                # â”€â”€ FedSpace â”€â”€
                elif self.strategy == "fedspace":
                    self._fedbuff_collect(sat_id, current_local_wrapper, event_time)
                    is_last = (i == len(all_events) - 1)
                    if self._fedspace_should_flush(event_time, len(self.gs_buffer), is_last):
                        self._fedspace_aggregate(temp_model, force_eval=is_last)

                # â”€â”€ FedOrbit â”€â”€
                elif self.strategy == "fedorbit":
                    plane = self.get_plane_id(sat_id)

                    if self.plane_masters.get(plane) == sat_id:
                        self._fedorbit_master_upload(sat_id, current_local_wrapper, event_time, temp_model)
                    else:
                        # ë¹„ë§ˆìŠ¤í„°: GS ì ‘ì´‰ ì‹œ ìµœì‹  ê¸€ë¡œë²Œ ë‹¤ìš´ë¡œë“œ
                        if self.global_model_wrapper.version > current_local_wrapper.version:
                            self.satellite_models[sat_id] = PyTorchModel.from_model(
                                self.global_model_net, version=self.global_model_wrapper.version
                            )
                            self.satellite_download_time[sat_id] = event_time
                            self.sim_logger.info(
                                f"   ğŸ“¥ SAT_{sat_id}: ê¸€ë¡œë²Œ v{self.global_model_wrapper.version} ë‹¤ìš´ë¡œë“œ"
                            )
                        self.satellite_last_trained_version[sat_id] = -1.0

        # ì”ì—¬ ë²„í¼ ì²˜ë¦¬
        if self.strategy in ("fedbuff", "fedspace") and len(self.gs_buffer) > 0:
            self._fedbuff_flush(temp_model, force_eval=True)

        # FedOrbit: ëª¨ë“  plane ì”ì—¬ ë²„í¼ ì²˜ë¦¬
        if self.strategy == "fedorbit":
            for plane_id in range(NUM_PLANES):
                if len(self.plane_buffers[plane_id]) > 0:
                    self.last_intra_agg_time[plane_id] = self.start_time
                    result = self._fedorbit_try_intra_aggregate(plane_id, self.end_time, temp_model)
                    if result:
                        self.aggregation_round += 1
                        nv = round(self.global_model_wrapper.version + 1.0, 1)
                        global_sd = self.global_model_wrapper.model_state_dict
                        eta_g = FEDORBIT_SERVER_LR
                        new_sd = OrderedDict()
                        for key in global_sd.keys():
                            if not self._is_gradient_param(key, global_sd[key]):
                                new_sd[key] = global_sd[key].clone()
                                continue
                            delta = global_sd[key].float() - result["state_dict"][key].float()
                            new_sd[key] = (global_sd[key].float() - eta_g * delta).to(global_sd[key].dtype).cpu()
                        self._update_global_and_evaluate(
                            new_sd, nv, result["participants"], temp_model, force_eval=True,
                            staleness_values=result["staleness_values"], sim_time=self.end_time,
                            plane_id=plane_id,
                        )

        # â”€â”€ ë©”íŠ¸ë¦­ ì €ì¥ ë° ì¶œë ¥ â”€â”€
        self.metrics.print_summary(len(self.satellites), logger=self.sim_logger)
        saved = self.metrics.save()
        self.sim_logger.info(f"ğŸ“ ê²°ê³¼ ì €ì¥: {saved}")

        self.sim_logger.info(f"\n=== ì‹œë®¬ë ˆì´ì…˜ ì¢…ë£Œ [{self.strategy.upper()}] ===")
        self.sim_logger.info(f"Total Aggregation Rounds: {self.aggregation_round}")
        self.sim_logger.info(f"Final Global Model Accuracy: {self.best_acc:.2f}%")


def parse_tle_epoch(tle_path: str = "constellation.tle") -> datetime:
    """TLE íŒŒì¼ì˜ ì²« ë²ˆì§¸ ìœ„ì„± epochì„ íŒŒì‹±í•˜ì—¬ datetime ë°˜í™˜.
    
    TLE Line 1 í˜•ì‹: 1 NNNNN ... YYDDD.DDDDDDDD ...
    - YY: 2ìë¦¬ ì—°ë„ (00-56 â†’ 2000+, 57-99 â†’ 1900+)
    - DDD.DDDDDDDD: ì†Œìˆ˜ì  í¬í•¨ day-of-year
    """
    with open(tle_path, "r") as f:
        for line in f:
            line = line.strip()
            if line.startswith("1 "):
                fields = line.split()
                epoch_str = fields[3]   # "26037.57365555"
                yy = int(epoch_str[:2])
                year = 2000 + yy if yy < 57 else 1900 + yy
                day_frac = float(epoch_str[2:])
                epoch = datetime(year, 1, 1, tzinfo=timezone.utc) + timedelta(days=day_frac - 1)
                return epoch
    raise ValueError(f"TLE epochì„ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {tle_path}")


def main():
    try:
        random.seed(SEED)
        np.random.seed(SEED)
        torch.manual_seed(SEED)
        torch.cuda.manual_seed_all(SEED)
        torch.backends.cudnn.deterministic = True
        torch.backends.cudnn.benchmark = False

        # ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘ ì‹œê°„ ê²°ì •
        if SIM_START_TIME is not None:
            start_time = SIM_START_TIME
        else:
            # TLE epoch ê¸°ë°˜ ìë™ ì„¤ì • (SGP4 ì •í™•ë„ + ì¬í˜„ì„± ë³´ì¥)
            start_time = parse_tle_epoch("constellation.tle")
        
        duration = timedelta(days=SIM_DURATION_DAYS)
        end_time = start_time + duration

        sim_logger, perf_logger = setup_loggers()
        sim_logger.info(f"ì‹œë®¬ë ˆì´ì…˜ ì‹œê°„: {start_time.isoformat()} ~ {end_time.isoformat()}")
        sim_logger.info(f"(TLE epoch ê¸°ë°˜, {SIM_DURATION_DAYS}ì¼ê°„)")

        sat_manager = Satellite_Manager(start_time, end_time, sim_logger, perf_logger)
        asyncio.run(sat_manager.run())
    except KeyboardInterrupt:
        print("\nì‹œë®¬ë ˆì´ì…˜ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
    except Exception as e:
        print(f"Error: {e}")


if __name__ == "__main__":
    main()